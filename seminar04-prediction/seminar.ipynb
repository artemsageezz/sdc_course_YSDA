{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292fe24e",
   "metadata": {},
   "source": [
    "## Предсказание траекторий автомобилей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c86102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87261e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"motion-prediction-video.mp4\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38511b1",
   "metadata": {},
   "source": [
    "## Соревнование https://research.yandex.com/shifts/vehicle-motion-prediction\n",
    "\n",
    "Трек по предсказанию траекторий движения автомобилей. Соревнование в целом посвящено исследованию подходов к оценке неопределенности и устойчивости моделей к сдвигам во входных данных.\n",
    "\n",
    "![Ансамбль моделей](uncertainty.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb39ade",
   "metadata": {},
   "source": [
    "## Что представляют из себя данные\n",
    "\n",
    "Единицей данных в датасете является сцена. Сцена содержит в себе информацию о динамических объектах (автомобилях и пешеходах), векторную карту дорожного графа, состояния светофоров, теги для сцены и отдельных агентов.\n",
    "\n",
    "Данные в сцене разбиты на две зоны: прошлое и будущее. Для каждого автомобиля нам известны следующие параметры:\n",
    "- уникальный идентификатор\n",
    "- положение в глобальной системе координат\n",
    "- размеры\n",
    "- скорость\n",
    "- ускорение\n",
    "\n",
    "Аналогичные данные известны для самого беспилотника. Для пешехедов данные ограничиваются id, положением, размером и скоростью.\n",
    "\n",
    "Дорожный граф содержит в себе информацию о полосах, полигон дороги, полигоны пешеходных переходов.\n",
    "\n",
    "Ссылка на тест сет, с которым поработаем на семинаре: https://disk.yandex.ru/d/M_4ED0r19OnSrg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70e9f5",
   "metadata": {},
   "source": [
    "## API для работы с датасетом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6b7d3",
   "metadata": {},
   "source": [
    "Рекомендую установить в virtualenv, чтобы не ставить лишние пакеты в хостовую систему.\n",
    "```\n",
    "git clone git@github.com:yandex-research/shifts.git\n",
    "cd shifts/sdc\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9848a9-556b-45ec-b4b1-6cc0206a90b7",
   "metadata": {},
   "source": [
    "Внимание!!! При такой установке может возникнуть проблема с тем, что старые(<=3.21) и новые версии протобуфа(>=4) несовместимы. Чтобы заработало, пришлось явно прописать некоторые версии при установке, файлик с новыми requirement.txt лежит рядом с ноутбуком. Версии из файлика также надо прописать в setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908385e",
   "metadata": {},
   "source": [
    "## Посмотрим на данные\n",
    "\n",
    "Исходные сырые данные хранятся в формате protubuf (https://developers.google.com/protocol-buffers), он позволяет удобно хранить и рабоать со структурированными объектами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ysdc_dataset_api.utils import read_scene_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = read_scene_from_file('test/011/011001.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Тип объекта: {type(scene)}')\n",
    "print(f'Поля объекта: {[field for field in dir(scene) if not field.startswith(\"_\") and field.islower()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69acc7",
   "metadata": {},
   "source": [
    "Каждая сцена содержит в себе данные о прошлом и будущем на 5 секунд (всего 10 секунд). Это время разбито на 50 дискретных таймстемпов с частотой  5Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd706f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Горизонт прошлого: {len(scene.past_vehicle_tracks)}, горизонт будущего: {len(scene.future_vehicle_tracks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27433c",
   "metadata": {},
   "source": [
    "Индекс 0 в past_tracks соответсвтует -5 секундам в истории, индекс 24 -- нулевая секунда, момент предсказния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Количество машин в момент предсказания: {len(scene.past_vehicle_tracks[-1].tracks)}')\n",
    "print('Информация об одной из машин в момент предсказания:')\n",
    "print(scene.past_vehicle_tracks[-1].tracks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d0eef",
   "metadata": {},
   "source": [
    "В сцене есть поле `prediction_requests` содержащее id автомобилей, для которых необходимо сделать предсказание. Помимо этого реквесты помечены тегами, описывающими характер движения автомобиля. Полный список тегов можно найти в файле `tags.proto` [ссылка](https://github.com/yandex-research/shifts/blob/main/sdc/ysdc_dataset_api/proto/tags.proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa197c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in scene.prediction_requests:\n",
    "    if r.track_id == scene.past_vehicle_tracks[-1].tracks[1].track_id:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb70c73",
   "metadata": {},
   "source": [
    "Тэги есть так же и у сцен. Они описывают различные срезы данных, по которым проходило разбиение в соревновании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5516a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scene.scene_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6006e7b-baca-4a1e-9fdc-14382cb578d8",
   "metadata": {},
   "source": [
    "### Про классы из библиотеки, которые мы будем использовать\n",
    "\n",
    "#### Для получения фичей из сцены есть 2 класса:\n",
    "- `FeatureRenderer(renderer_config)` -- объект, который описывает генерацию фичей мапы по сцене\n",
    "- `FeatureVectorizer(vectorizer_config)` -- объект, который описывает генерацию векторных фичей из истории агентов\n",
    "\n",
    "Примеры конфигов для генерации фичей лежат рядом с ноутбуком\n",
    "\n",
    "#### Для работы со сценами как с датасетом есть класс \n",
    "```\n",
    "MotionPredictionDataset(\n",
    "    dataset_path: str,\n",
    "    prerendered_dataset_path: str,\n",
    "    feature_producers: List[Union[FeatureRenderer, FeatureVectorizer]],\n",
    "    transform_ground_truth_to_agent_frame: bool\n",
    ")\n",
    "```\n",
    "`dataset_path` -- путь до датасета \\\n",
    "`prerendered_dataset_path` -- путь до датасета c пререндеренными картинками \\\n",
    "`feature_producers` -- cписок векторайзеров и рендереров для генерации фичей. При добавлении пререндеренных фичей их рендерер указывать не надо \\\n",
    "`transform_ground_truth_to_agent_frame` -- переводить ли сцену в систему координат агента\n",
    "\n",
    "В нашем случае пререндеренные фичи лежат там же, где и объекты. `<scene>.pb` -- сцена, `<scene>.npy` -- пререндеренные фичи для сцены."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25da3e",
   "metadata": {},
   "source": [
    "Давайте нарисуем уже сцену и посмотрим, как оно выглядит не в скучных числах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "from ysdc_dataset_api.dataset import MotionPredictionDataset\n",
    "from ysdc_dataset_api.features import FeatureRenderer\n",
    "from ysdc_dataset_api.utils import transform_2d_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('renderer_config.yaml') as f:\n",
    "    renderer_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = FeatureRenderer(renderer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    feature_producers=[renderer],\n",
    "    transform_ground_truth_to_agent_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Количество сцен в датасете: {dataset.num_scenes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738eda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)\n",
    "\n",
    "# Проитерируемся по датасету в поисках машины, проехавшей более 10 метров по обеим из координат.\n",
    "while True:\n",
    "    data_item = next(dataset_iter)\n",
    "    if data_item['ground_truth_trajectory'][-1, 0] > 10.0 and data_item['ground_truth_trajectory'][-1, 1] > 10.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Датасет для каждого объекта возвращает набор следующих полей: {[k for k in data_item.keys()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Размеры фичемап, которые нам отдал рендерер: {data_item[\"feature_maps\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ec110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(data_item['feature_maps'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(data_item['feature_maps'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(data_item['feature_maps'][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(data_item['feature_maps'][16], origin='lower', cmap='binary', alpha=0.1)\n",
    "\n",
    "# Переведем ground truth траекторию агента в систему координат фичемапы\n",
    "transformed_gt = transform_2d_points(data_item['ground_truth_trajectory'], renderer.to_feature_map_tf)\n",
    "transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_collection(mc.LineCollection([transformed_gt], color='green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fe5db",
   "metadata": {},
   "source": [
    "## Метрики\n",
    "\n",
    "Одними из общепринятых метрик для оценки качества предсказания траекторий являются Average Displacement Error и Final Displacement Error, а так же их модификации minADE@k, minFDE@k:\n",
    "- ADE - среднее по таймстемпам L2 отклонеие предсказания от ground truth\n",
    "- FDE - L2 отклонение последней предсказанной точки траектории от ground truth\n",
    "- minADE@k -- минимальное значение ADE по k наиболее вероятных предсказанных гипотез\n",
    "- minFDE@k -- минимальное значение FDE по k наиболее вероятных предсказанных гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ca910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for ADE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fde(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for FDE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b73715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_ade(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for minADE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_modes, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_fde(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for minFDE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_modes, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cc8cd",
   "metadata": {},
   "source": [
    "## Модель с константным предсказанием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from ysdc_dataset_api.features import FeatureVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b30f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, gt_time_grid):\n",
    "        super().__init__()\n",
    "        self._gt_time_grid = torch.tensor(gt_time_grid)\n",
    "    \n",
    "    def forward(self, velocity):\n",
    "        states = torch.einsum('bc,t->btc', velocity, self._gt_time_grid)\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(np.linspace(0.2, 5, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d851c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer_config.yaml') as f:\n",
    "    vectorizer_config = yaml.safe_load(f)\n",
    "vectorizer = FeatureVectorizer(vectorizer_config)\n",
    "\n",
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path='test/',\n",
    "    prerendered_dataset_path='test/',\n",
    "    feature_producers=[vectorizer],\n",
    "    transform_ground_truth_to_agent_frame=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf563ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ades = []\n",
    "fdes = []\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    # Возьмём скорость по (x, y) в последний известный момент времени\n",
    "    predictions = model(batch['vector_features'][:, -1, 2:4])\n",
    "    ades.append(ade(batch['ground_truth_trajectory'], predictions))\n",
    "    fdes.append(fde(batch['ground_truth_trajectory'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.concatenate(ades)), np.mean(np.concatenate(fdes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7546a6",
   "metadata": {},
   "source": [
    "## Визуализация предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тк в датасете выше мы использовали готовые пре-рендеренные картинки (см prerendered_dataset_path),\n",
    "# сделаем себе соответсвующий рендерер, чтобы извлечь из него трансформ для визуализации.\n",
    "with open('prerendered_images_config.yaml') as f:\n",
    "    renderer_config = yaml.safe_load(f)\n",
    "renderer = FeatureRenderer(renderer_config)\n",
    "\n",
    "\n",
    "# Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "i = 1\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(batch['prerendered_feature_map'][i][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][16], origin='lower', cmap='binary', alpha=0.1)\n",
    "\n",
    "# Переведем ground truth траекторию агента в систему координат фичемапы\n",
    "transformed_gt = transform_2d_points(batch['ground_truth_trajectory'][i].numpy(), renderer.to_feature_map_tf)\n",
    "transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_collection(mc.LineCollection([transformed_gt], color='green'))\n",
    "\n",
    "prediction = predictions[i].numpy().astype(np.float32)\n",
    "transformed_prediction = transform_2d_points(prediction, renderer.to_feature_map_tf)\n",
    "ax.add_collection(mc.LineCollection([transformed_prediction], color='red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09784a4b",
   "metadata": {},
   "source": [
    "## Мультимодальность\n",
    "\n",
    "#### Общий подход\n",
    "Теперь мы предсказываем распределение на траекториях\n",
    "$$\n",
    "trajectory \\sim \\sum\\limits_{i=1}^{M} p_i q(mode_i)\n",
    "$$\n",
    "где $p_i$ -- вероятность $i$-ой моды,  $q(mode_i)$ -- некоторое распределение значений $i$-ой моды\n",
    "\n",
    "#### Имплементация\n",
    "- В одномодальном случае мы предсказывали траекторию из некоторого промежуточного состояния(эмебддинга) некоторой головой.\n",
    "- В многомодальном случае мы из того же самого эмбеддинга предсказываем несколько голов, каждая голова отвечает за свою моду. Дополнительно из эмбеддинга предсказываем логиты, из которых получим вероятности реализации мод.\n",
    "#### Лосс\n",
    "Обозначи за $gt$ -- ground truth траекторию, $mode_i$ -- предсказанное значение $i$-ой моды \\\n",
    "Пусть $\\widehat{i}$ -- индекс моды с ближайшим к GT предсказанием(т. е.  $\\widehat{i} = \\arg\\min\\limits_i ADE(mode_i, gt)$) \n",
    "- Взвешенный ADE\n",
    "$$loss = \\sum\\limits_{i=1}^{M} p_i ADE(mode_i, gt)$$\n",
    "может сходиться к предсказанию с нулевыми вероятностями всех мод кроме одной\n",
    "- ADE для ближайшей траектории + классификация ближайшей траектории \\\n",
    "$$loss = -\\log{p_{\\widehat{i}}} + \\alpha ADE(mode_{\\widehat{i}}, gt)$$\n",
    "- GMM(Gaussian mixture model) \\\n",
    "Модель предсказывает для моды с индексом $i$ среднее и стандартное отклонение ($\\mu_{i}$, $\\sigma_{i}$)\n",
    "$$loss = -\\log{p_{\\widehat{i}}} - \\alpha \\log{\\mathcal{N}(gt | \\mu_{\\widehat{i}}, \\sigma_{\\widehat{i}})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675c9b9-df8c-48b3-b7b8-185947a5d4c7",
   "metadata": {},
   "source": [
    "## Практические аспекты\n",
    "\n",
    "### Типичная схема сети для multitask learning\n",
    "\n",
    "![Схема моделей](schema.png)\n",
    "\n",
    "#### Виды голов\n",
    "- Траектория\n",
    "- Интент (стационарность, уступание, движение задним ходом и т д)\n",
    "- Обусловленная траектория:\n",
    "  - На интент. Данная голова сожержит траектории для всех значений интента. Каждая траектория обучается на подмножестве данных, где реализовалось соответствующее значение интента\n",
    "  - На траекторию. Подмешиваем к эмбеддингу предсказываемого агента эмбеддинг траектории(это может быть траектория ровера, lane path и т д)\n",
    "\n",
    "Чем больше адекватных голов, тем лучше. Используем multitask learning. \n",
    "\n",
    "#### Двустадийность \n",
    "В продакшне мы ограничены требованиями к задержкам системы и должны выдавать траектории за определенное время. Для того, чтобы была возможность увеличить сетку без увеличения задержек, можно использовать следующий подход:\n",
    "- Используем выход энкодера графа дорог и другой медленно меняющейся информации с предыдущего тика.\n",
    "- Для быстро изменяющихся фичей агентов считаем данные с текущего тика\n",
    "- Опционально можно добавить смещение нашей позиции за тик, чтобы помочь сетке понимать, как изменился граф полос с предыдущего тика\n",
    "\n",
    "#### Данные\n",
    "- Проезды водителей \"на руках\"\n",
    "- Автоматические проезды:\n",
    "  -  active learning, семплируем моменты, где ошиблась текущая модель\n",
    "      - Ни одна мода не лежит в окрестности наблюдаемой траектории агента\n",
    "      - Неправильно определен интент\n",
    "  - интересные моменты (с сдвигами назад и вперед)\n",
    "      - перестроение\n",
    "      - проехали пешеходный переход\n",
    "      - объезд препятствия\n",
    "      - замедления\n",
    "      - ускорения\n",
    "      - и т д "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52212b-8e63-4b61-ba58-73636a119b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17eb708",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff230e9e",
   "metadata": {},
   "source": [
    "В качестве задания предлагается обучить нейросетку для предсказания траекторий и побить наш бейзлайн. В качестве решения ожидается тетрадка с кодом (которым можно воспроизвести полученные результаты). Тетрадка также должна содержать подробный отчёт о рассмотренных подходах, сравнение подходов на тесте между собой, а также с бейзлайном.\n",
    "Ссылки на данные:\n",
    "- [трейн](https://disk.yandex.ru/d/tuTwRSLL-KFqjg)\n",
    "- [валидация](https://disk.yandex.ru/d/3Lu6_6BgwkXlgw)\n",
    "- [тест](https://disk.yandex.ru/d/M_4ED0r19OnSrg)\n",
    "\n",
    "Нужно провести следующие эксперименты:\n",
    "1. Обучить любую нейросетевую модель(без добавления картинок/векторного представления графа), которая сошлась и предсказывает визуально разумные траектории **(4 балла)**\n",
    "2. Обучить сетку с добавлением картинок/векторного представления графа, правда если от добавления сигнала стало хуже, ставим 0 баллов **(4 балла)**\n",
    "3. Обучить мультимодальное предсказание, если вы покажете хотя бы один пример, где гипотезы заметно отличаются и при этом у обоих гипотез не околонулевые вероятности. Кроме того, minADE этой сетки должен быть лучше, чем сетки из пункта 2 **(2 балла)**\n",
    "\n",
    "В каждом пункте нужны картинки, без картинок будем снижать баллы\n",
    "Если в каком-то пункте предсказание на тесте получилось хуже кинематического предсказания (бейзлайна с семинара), то оценку за пункт делим на 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для использования картиночных фичей можно использовать уже нарендеренные картинки (они есть в датасете).\n",
    "# Рендерить с нуля может быть довольно долго.\n",
    "# Пример использования готовых картинок в датасете:\n",
    "\n",
    "# dataset = MotionPredictionDataset(\n",
    "#     dataset_path='test/',\n",
    "#     prerendered_dataset_path='test/',  # Тут мы указываем путь, где искать готовые картинки\n",
    "#     feature_producers=[vectorizer],\n",
    "#     transform_ground_truth_to_agent_frame=True,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
